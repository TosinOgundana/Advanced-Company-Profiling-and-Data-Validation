{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52015e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1eb8028",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff99ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Display the first few rows to understand the data\n",
    "df = pd.read_csv('Company.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "df.info()\n",
    "\n",
    "# print dataset number of rows and column\n",
    "print('This dataset contains', df.shape[0], 'rows and', df.shape[1], 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values per Column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83337bf7",
   "metadata": {},
   "source": [
    "In the above sections, the provided `Company.csv` file was loaded into a pandas DataFrame for initial exploration. Also review basic information such as missing values, duplicate entries, and a statistical summary of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fce47",
   "metadata": {},
   "source": [
    "## Data Cleaning and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaeb5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Strip leading/trailing spaces from object-type text fields\n",
    "object_cols = df.select_dtypes(include='object').columns\n",
    "for col in object_cols:\n",
    "    df[col] = df[col].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b57e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling invalid inputs\n",
    "\n",
    "# Get the row as a Series\n",
    "row = df.iloc[11]\n",
    "\n",
    "# Shift the values 6 positions to the right\n",
    "shifted_row = row.shift(periods=6)\n",
    "\n",
    "# Replace the original row with the shifted row\n",
    "df.iloc[11] = shifted_row\n",
    "\n",
    "# Filled company number from URI Link\n",
    "df.at[11, 'CompanyNumber'] = '01477370'\n",
    "\n",
    "# Confirm the changes\n",
    "#print(df.iloc[11])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6303e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns with too many missing values (benchmark: more than 90% missing)\n",
    "\n",
    "benchmark = 0.9\n",
    "missing_ratio = df.isnull().mean()\n",
    "columns_to_drop = missing_ratio[missing_ratio > benchmark].index\n",
    "df_cleaned = df.drop(columns=columns_to_drop)\n",
    "\n",
    "print(f\"Columns dropped due to high missing ratio: {list(columns_to_drop)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(col):\n",
    "    # Remove schema prefixes (e.g., 'RegAddress.')\n",
    "    col = col.split('.')[-1]\n",
    "    # Convert to snake_case\n",
    "    col = re.sub(r'(?<=[a-z])(?=[A-Z0-9])|(?<=[A-Z])(?=[A-Z][a-z])', '_', col).lower()\n",
    "    return col\n",
    "\n",
    "# Apply to dataframe\n",
    "df_cleaned.columns = [clean_column_name(col) for col in df_cleaned.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize both country and country_of_origin fields\n",
    "\n",
    "# Define a mapping for country name standardization\n",
    "country_mapping = {\n",
    "    'UK': 'United Kingdom',\n",
    "    'ENGLAND': 'United Kingdom',\n",
    "    'england': 'United Kingdom',\n",
    "    'SCOTLAND': 'United Kingdom',\n",
    "    'WALES': 'United Kingdom',\n",
    "    'NORTHERN IRELAND': 'United Kingdom'\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "# Apply mapping to country if it exists\n",
    "if 'country' in df_cleaned.columns:\n",
    "    df_cleaned['country'] = df_cleaned['country'].replace(country_mapping)\n",
    "\n",
    "# Apply mapping to country_of_origin if it exists\n",
    "if 'country_of_origin' in df_cleaned.columns:\n",
    "    df_cleaned['country_of_origin'] = df_cleaned['country_of_origin'].replace(country_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bf47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conditional_title(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.title()\n",
    "    return x\n",
    "\n",
    "columns_to_title = [col for col in df_cleaned.columns if col not in ['post_code', 'company_name', 'uri']]\n",
    "\n",
    "for col in columns_to_title:\n",
    "    df_cleaned[col] = df_cleaned[col].apply(conditional_title)\n",
    "\n",
    "\n",
    "df_cleaned['post_code'] = df_cleaned['post_code'].str.upper()\n",
    "df_cleaned['company_name'] = df_cleaned['company_name'].str.upper()\n",
    "df_cleaned['company_number'] = df_cleaned['company_number'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d4322",
   "metadata": {},
   "source": [
    "## Deduplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. First, check if 'company_number' has any missing values\n",
    "missing_company_numbers = df_cleaned['company_number'].isnull().sum()\n",
    "print(f\"Missing Company Numbers: {missing_company_numbers}\")\n",
    "\n",
    "# 2. Identify duplicate Company Numbers\n",
    "duplicates = df_cleaned.duplicated(subset='company_number', keep=False)\n",
    "\n",
    "print(f\"\\nNumber of Potential Duplicate Records based on company number: {duplicates.sum()}\")\n",
    "\n",
    "# 3. View duplicate records if you want to inspect\n",
    "df_cleaned[duplicates].sort_values(by='company_number')\n",
    "\n",
    "# 4. Drop duplicates, keeping the first occurrence\n",
    "df_cleaned = df_cleaned.drop_duplicates(subset='company_number', keep='first')\n",
    "\n",
    "print(f\"\\nDataset shape after removing duplicates: {df_cleaned.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff5114",
   "metadata": {},
   "source": [
    "## Setup - Companies House API Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe5a9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Companies House API key\n",
    "API_KEY = '614c43c4-f999-453e-b07d-3652f55ebf63'\n",
    "\n",
    "def query_companies_house_by_number(company_number):\n",
    "    try:\n",
    "        if pd.isnull(company_number):\n",
    "            return {\n",
    "                'api_match_found': False,\n",
    "                'api_company_number': '',\n",
    "                'api_company_status': '',\n",
    "                'api_incorporation_date': '',\n",
    "                'api_title': '',\n",
    "                'api_address_line_1': '',\n",
    "                'api_address_line_2': '',\n",
    "                'api_postal_code': '',\n",
    "                'api_locality': '',\n",
    "                'api_country': ''\n",
    "            }\n",
    "        \n",
    "        # Call Company Profile API directly\n",
    "        profile_response = requests.get(\n",
    "            f'https://api.company-information.service.gov.uk/company/{company_number}',\n",
    "            auth=(API_KEY, '')\n",
    "        )\n",
    "        \n",
    "        if profile_response.status_code == 404:\n",
    "            print(f\"Company {company_number} not found. (404)\")\n",
    "            return {\n",
    "                'api_match_found': False,\n",
    "                'api_company_number': company_number,\n",
    "                'api_company_status': '',\n",
    "                'api_incorporation_date': '',\n",
    "                'api_company_name': '',\n",
    "                'api_address_line_1': '',\n",
    "                'api_address_line_2': '',\n",
    "                'api_postal_code': '',\n",
    "                'api_locality': '',\n",
    "                'api_country': ''\n",
    "            }\n",
    "        \n",
    "        profile_response.raise_for_status()\n",
    "        profile_data = profile_response.json()\n",
    "        \n",
    "        registered_address = profile_data.get('registered_office_address', {})\n",
    "        \n",
    "        return {\n",
    "            'api_match_found': True,\n",
    "            'api_company_number': company_number,\n",
    "            'api_company_status': profile_data.get('company_status', ''),\n",
    "            'api_incorporation_date': profile_data.get('date_of_creation', ''),\n",
    "            'api_company_name': profile_data.get('company_name', ''),\n",
    "            'api_address_line_1': registered_address.get('address_line_1', ''),\n",
    "            'api_address_line_2': registered_address.get('address_line_2', ''),\n",
    "            'api_postal_code': registered_address.get('postal_code', ''),\n",
    "            'api_locality': registered_address.get('locality', ''),\n",
    "            'api_country': registered_address.get('country', '')\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error querying {company_number}: {e}\")\n",
    "        return {\n",
    "            'api_match_found': False,\n",
    "            'api_company_number': company_number,\n",
    "            'api_company_status': '',\n",
    "            'api_incorporation_date': '',\n",
    "            'api_company_name': '',\n",
    "            'api_address_line_1': '',\n",
    "            'api_address_line_2': '',\n",
    "            'api_postal_code': '',\n",
    "            'api_locality': '',\n",
    "            'api_country': ''\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77a642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply the updated function using company_number column\n",
    "api_results = df_cleaned['company_number'].apply(query_companies_house_by_number)\n",
    "\n",
    "# Convert to DataFrame\n",
    "api_results_df = pd.json_normalize(api_results)\n",
    "\n",
    "# Merge back with cleaned dataset\n",
    "df_final = pd.concat([df_cleaned.reset_index(drop=True), api_results_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "df_final['country'] = df_final['country'].fillna('United Kingdom')\n",
    "\n",
    "# Display result\n",
    "df_final.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa5c97",
   "metadata": {},
   "source": [
    "# Matching Information Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Select key columns\n",
    "contact_info = df_final[[\n",
    "    'company_name', 'api_company_name', 'company_number','api_company_number',\n",
    "    'address_line_1','api_address_line_1', 'api_address_line_2',\n",
    "    'api_locality', 'post_code', 'api_postal_code', 'country', 'api_country'\n",
    "]]\n",
    "\n",
    "# Quick check on match completeness\n",
    "total_records = contact_info.shape[0]\n",
    "name_matches = contact_info['api_company_name'].notnull().sum()\n",
    "number_matches = contact_info['api_company_number'].notnull().sum()\n",
    "address_matches = contact_info['api_address_line_1'].notnull().sum()\n",
    "postcode_matches = contact_info['api_postal_code'].notnull().sum()\n",
    "\n",
    "# Print Summary\n",
    "print(f\"Simple Matching Summary:\")\n",
    "print(f\"- Total Records: {total_records}\")\n",
    "print(f\"- Company Name Matches: {name_matches} ({round(name_matches/total_records*100, 2)}%)\")\n",
    "print(f\"- Company Name Matches: {number_matches} ({round(number_matches/total_records*100, 2)}%)\")\n",
    "print(f\"- Address Line 1 Matches: {address_matches} ({round(address_matches/total_records*100, 2)}%)\")\n",
    "print(f\"- Postal Code Matches: {postcode_matches} ({round(postcode_matches/total_records*100, 2)}%)\")\n",
    "\n",
    "# Display first few matched records\n",
    "contact_info.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final matched contact information to CSV\n",
    "contact_info.to_csv('final_matched_contact_info.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
